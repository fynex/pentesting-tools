#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import requests
import argparse
from bs4 import BeautifulSoup


BLACKLIST = {"a", "the", "in", "on", "a", "he", "she", "it", "its", "i",
             "by", "to",
             "der", "die", "das", "wir", "ihr", "sie", "in", "im",
             "auf", "von", "er", "sie", "es",
             "a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p",
             "q","r","s","t","u","v","w","x","y","z",}

word_strip = [".", ",", "'s"]

def add_to_counter_dict(e, counter_dict):
    if e in counter_dict:
        counter_dict[e] = counter_dict[e] + 1
    else:
        counter_dict[e] = 1

def in_blacklist(e):
    return e.lower() in BLACKLIST

def user_needs_only_upper(e):
    return args.only_upper and not e[0].isupper()

def clean_value(e):
    e = e.strip()
    e = e.replace("\n", "")

    for ws in word_strip:
        e = e.strip(ws)

    return e


### Main ###
parser = argparse.ArgumentParser(description="DESC")
parser.add_argument("-u", "--url", required=True, help="The URL of the page to retrieve information from")
parser.add_argument("-o", "--only-upper", action="store_true", default=False, help="Filters the result only for capitalized")

args = parser.parse_args()

r        = requests.get(args.url)
html_doc = r.text

soup = BeautifulSoup(html_doc, 'html.parser')
text = soup.text # text which contains js....

words = {}

for e in text.split(" "):
    e = clean_value(e)

    if e:
        if user_needs_only_upper(e):
            continue

        if not in_blacklist(e):
            add_to_counter_dict(e, words)

sorted_dict = sorted(words.items(), key=lambda x: x[1])
sorted_dict = list(reversed(sorted_dict))

for e in sorted_dict:
    if e[1] > 1:
        print(e[0])
